{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_validate\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_decomposition\n",
    "import plotly.express as px "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url =  \"https://raw.githubusercontent.com/Naio/aasa-stability-prediction/master/data/processed/\"\n",
    "#Seed for controlling any random procedure during the experiments\n",
    "seed = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares = linear_model.LinearRegression()\n",
    "ridge = linear_model.Ridge(random_state=seed)\n",
    "lasso = linear_model.Lasso()\n",
    "pls = cross_decomposition.PLSRegression()\n",
    "svr = svm.SVR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining hyperparameter grids\n",
    "Each algorithm has its corresponding hyperparameter grid for later use in grid search inner cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares_grid = {} #Ordinary least square doesn't have hyperparamters\n",
    "\n",
    "ridge_grid = {'alpha' : np.logspace(-6, 6, 13)} #Alpha between 1.e-06 and 1.e+06\n",
    "lasso_grid = {'alpha' : np.logspace(-6, 6, 13)} \n",
    "pls_grid = {'n_components': np.linspace(start = 2, stop=25, num=24).astype(int)} #Between 2 and 25 Principal Components\n",
    "\n",
    "svr_grid = [\n",
    "    #Grid for linear kernel\n",
    "    {'C': np.logspace(-6, 6, 13), 'kernel': ['linear']},\n",
    "    #Grid for rbf and sigmoid kernel\n",
    "    {'C': np.logspace(-6, 6, 13), 'gamma': np.logspace(-6, 6, 13), 'kernel': ['rbf', 'sigmoid']},\n",
    "    #Grid for polinomial kernel\n",
    "    {'C': np.logspace(-6, 6, 13), 'gamma': np.logspace(-6, 6, 13), 'kernel': ['poly'], 'degree': [2,3,4]}\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping each estimator with its hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_methods = [{'name': 'OLS', 'estimator':least_squares, 'hyperparameter_grid': least_squares_grid},\n",
    "                    {'name': 'RIDGE','estimator':ridge, 'hyperparameter_grid': ridge_grid},\n",
    "                    {'name': 'LASSO', 'estimator':lasso, 'hyperparameter_grid': lasso_grid},\n",
    "                    {'name': 'SVR', 'estimator':svr, 'hyperparameter_grid': svr_grid},\n",
    "                    {'name': 'PLS', 'estimator':pls, 'hyperparameter_grid': pls_grid}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets():\n",
    "    \n",
    "    datasets_names = ['A.csv', 'B.csv', 'C.csv', 'D.csv']\n",
    "    \n",
    "    for dataset_name in datasets_names:\n",
    "        protein_dataset = pd.read_csv(data_url + dataset_name)\n",
    "        proteins_X = protein_dataset.iloc[:, 1:].to_numpy()\n",
    "        proteins_X = preprocessing.scale(proteins_X) #Z-Score standarization\n",
    "        proteins_y = protein_dataset.iloc[:,0].to_numpy()\n",
    "        \n",
    "        yield {'name': dataset_name, 'features': proteins_X, 'target': proteins_y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The nested_cv function returns a dictionary like with the outer cross-validation loop scores for every learning method.\n",
    "#The dictionary looks like:\n",
    "#{\n",
    "#    'r2': {'PLS': [0.99,...,0.67], 'SVR': [0.94,..., 0.98], ... , 'OLS': [0.4, ..., 0.32]}, \n",
    "#  'rmse': {'PLS': [1.297116,...,2.297116], 'SVR': [1.291,..., 0.29471], ... , 'OLS': [3.19283, ..., 5.827391]}\n",
    "#}\n",
    "def nested_cv(features, target):\n",
    "    \n",
    "    #Score metric used for hyperparameter optimization in inner CV loop\n",
    "    inner_scoring = 'r2'\n",
    "    \n",
    "    #Score metrics used in outer CV loop for generalization performance estimation of the learning method \n",
    "    outer_scoring = ['r2', 'neg_root_mean_squared_error']\n",
    "    \n",
    "    outer_scores_r2 = {}\n",
    "    outer_scores_rmse = {}\n",
    "    \n",
    "    for learning_method in learning_methods:\n",
    "        inner_cv = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        outer_cv = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "        #Inner CV estimator\n",
    "        est = GridSearchCV(estimator = learning_method['estimator'], \n",
    "                           param_grid = learning_method['hyperparameter_grid'], \n",
    "                           cv = inner_cv, \n",
    "                           scoring = inner_scoring,\n",
    "                           #When n_jobs is -1, all CPUs are used to run cross-validation in parallel\n",
    "                           n_jobs=-1)\n",
    "\n",
    "        #For each train-test dataset split in the outer cross validation loop, \n",
    "        #cross_validate function will call the fit() method of the GridSearchCV estimator.\n",
    "        outer_cv_results = cross_validate(estimator = est, \n",
    "                                          X = features, y = target, \n",
    "                                          cv = outer_cv, scoring = outer_scoring)\n",
    "        \n",
    "        outer_scores_r2[learning_method['name']] = outer_cv_results['test_r2']\n",
    "        \n",
    "        #Inside CV, the RSME score is managed as a negative RMSE. Multiplying it by -1 will turn it into the usual positive RMSE  \n",
    "        outer_scores_rmse[learning_method['name']] = outer_cv_results['test_neg_root_mean_squared_error']*-1 \n",
    "       \n",
    "    return {'r2': outer_scores_r2, 'rmse':outer_scores_rmse}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Can't use statement directly after '%%time'!\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#For each dataset (A,B,C,D)\n",
    "for dataset in datasets():\n",
    "    outer_scores = nested_cv(dataset['features'], dataset['target'])\n",
    "    \n",
    "    outer_scores_df = pd.DataFrame(outer_scores['r2'])\n",
    "    #Export scores to Latex table\n",
    "    outer_scores_df.to_latex(buf='./RSquared_r2_scores_' + dataset['name'] + '.txt', index_names= False,\n",
    "                            caption=\"RSquared scores for dataset\" + dataset['name'])\n",
    "    \n",
    "    outer_scores_df = pd.DataFrame(outer_scores['rmse'])\n",
    "    outer_scores_df.to_latex(buf='./RSquared_rmse_scores_' + dataset['name'] + '.txt', index_names=False,\n",
    "                            caption=\"RMSE scores for dataset\" + dataset['name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
