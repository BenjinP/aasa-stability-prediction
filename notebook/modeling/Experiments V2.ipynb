{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all related to predictive modeling and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methodology used is an adaptation of Crisp-DM. Currently, we are the steps Modeling and Evaluation:\n",
    "1. Domain Understanding\n",
    "2. Data Understanding\n",
    "4. Data Preparation\n",
    "5. **Modeling**\n",
    "6. **Evaluation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_validate, RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import minmax_scale, scale\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest,  f_regression, mutual_info_regression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.decomposition import PCA\n",
    "from skrebate import ReliefF, SURF\n",
    "from sklearn.datasets import load_boston, load_diabetes, fetch_california_housing\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_url =  \"https://raw.githubusercontent.com/Naio/aasa-stability-prediction/master/data/processed/\"\n",
    "seed = 10 #Seed for controlling any random procedure during the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator that yields ready-to-use datasets\n",
    "def datasets():\n",
    "    datasets_names = ['p1STN', 'p4LYZ', 'p1BPI', 'HLYZ']\n",
    "    data_url = 'https://raw.githubusercontent.com/Naio/aasa-stability-prediction/master/data/processed/original/'\n",
    "    \n",
    "    for dataset_name in datasets_names:\n",
    "        protein_dataset = pd.read_csv(data_url + dataset_name + '.csv')\n",
    "        protein_dataset = preprocess_dataset(protein_dataset)\n",
    "        features, target = split_features_and_target(protein_dataset)\n",
    "        \n",
    "        yield {'name': dataset_name, 'features': features, 'target': target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(df):\n",
    "    \n",
    "    #Discard of those descriptors that are highly correlated\n",
    "    df = discard_highly_correlated_descriptors(df)\n",
    "    \n",
    "    #Feature selection\n",
    "    #Note: This implementation is able to work even if data is not normalized.\n",
    "    df = select_subset_of_features_SURF(df, number_of_features)\n",
    "    \n",
    "    #Z-Score Normalization\n",
    "    df = normalize_data(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discards descriptors that are highly correlated at least with one other descriptor.\n",
    "#The threshold is an absolute Pearson's r greater than 0.99 \n",
    "def discard_highly_correlated_descriptors(df):\n",
    "    \n",
    "    #Calculates the absolute Pearson's r correlation matrix. Both -1 and 1 are highly correlated.\n",
    "    correlations = df.corr().abs()\n",
    "    \n",
    "    #Gets the correlation matrix upper triangular.\n",
    "    upper_corr = correlations.where(np.triu(np.ones(correlations.shape), k=1).astype(np.bool))\n",
    "    \n",
    "    #Discards the descriptors\n",
    "    to_drop = [column for column in upper_corr.columns if any(upper_corr[column] > 0.99)]\n",
    "    return df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_subset_of_features_SURF(df, n_features):\n",
    "    features_importance = calculate_features_importance(df, n_features)\n",
    "    selected_features = select_n_most_important_features(features_importance, n_features)\n",
    "    filtered_df = filter_selected_columns(df, selected_features)\n",
    "    return filtered_df\n",
    "\n",
    "def calculate_features_importance(df, n_features):\n",
    "    features, target = split_features_and_target(df)\n",
    "    \n",
    "    rlf = SURF(n_features_to_select=n_features)\n",
    "    rlf.fit(features, target)\n",
    "    \n",
    "    return pd.DataFrame({'feature_name':df.iloc[:, 2:].columns, \n",
    "                         'importance': rlf.feature_importances_})\n",
    "\n",
    "def select_n_most_important_features(features_importance, n_features):\n",
    "    return features_importance.sort_values(by='importance', ascending=False).head(n_features)['feature_name'].tolist()\n",
    "\n",
    "def filter_selected_columns(df, columns):\n",
    "    selected = ['id', 'stability']\n",
    "    selected.extend(columns)\n",
    "    return df[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a dataset with normalized descriptors using Z-Score\n",
    "def normalize_data(df):\n",
    "    \n",
    "    #Only descriptores are normalized, so we set apart the stability and mutation name attributes from the original dataset\n",
    "    mutation_stability = df.iloc[:, 0:2]\n",
    "    \n",
    "    #Setting apart the descriptors data\n",
    "    descriptors = df.iloc[:, 2:]\n",
    "                      \n",
    "    #Normalizing the descriptors using Z-Score\n",
    "    normalized_descriptors = pd.DataFrame(scale(descriptors), columns=descriptors.columns)\n",
    "    \n",
    "    #Joining stability and mutation name to the normalized descriptors\n",
    "    normalized_data = mutation_stability.join(normalized_descriptors)\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns descriptors and target values as numpy arrays\n",
    "def split_features_and_target(df):\n",
    "    features = df.iloc[:, 2:].to_numpy()\n",
    "    target =  df.iloc[:,1].to_numpy()\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining hyperparameter grids\n",
    "Each algorithm has its corresponding hyperparameter grid for later use in grid search inner cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares_grid = {} #Ordinary least square doesn't have hyperparamters\n",
    "\n",
    "alpha_range = np.logspace(-6, 6, 13)\n",
    "ridge_grid = {'alpha' : alpha_range} #Alpha between 1.e-06 and 1.e+06\n",
    "lasso_grid = {'alpha' : alpha_range} \n",
    "\n",
    "pls_grid = {'n_components': np.linspace(start = 2, stop=25, num=100).astype(int)} #Between 2 and 25 Principal Components\n",
    "c_range = np.logspace(-6, 6, 13) #Between 1.e-05 and 1.e+02. Lower C, more regularization. np.logspace(-3, 3, 7)\n",
    "gamma_range = np.logspace(-6, 6, 13)\n",
    "epsilon_range = np.linspace(start = 1.0, stop=2.5, num=16)#np.linspace(start = 1.0, stop=2.5, num=16)\n",
    "svr_grid = [\n",
    "    #Grid for rbf and sigmoid kernel\n",
    "    {'C': c_range, 'gamma': gamma_range, 'kernel': ['rbf'], 'epsilon': epsilon_range},\n",
    "    #Grid for polinomial kernel\n",
    "    {'C': c_range, 'gamma': gamma_range, 'kernel': ['poly'], 'degree': [2,3], 'epsilon': epsilon_range}\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smaller Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares_grid = {} #Ordinary least square doesn't have hyperparamters\n",
    "\n",
    "alpha_range = np.logspace(-6, 6, 13)\n",
    "ridge_grid = {'alpha' : alpha_range} #Alpha between 1.e-06 and 1.e+06\n",
    "lasso_grid = {'alpha' : alpha_range} \n",
    "\n",
    "pls_grid = {'n_components': np.linspace(start = 2, stop=25, num=100).astype(int)} #Between 2 and 25 Principal Components\n",
    "c_range = np.logspace(-3, 3, 7) #np.logspace(-3, 3, 7)\n",
    "gamma_range = np.logspace(-3, 3, 7)\n",
    "#epsilon_range = np.linspace(start = 0.5, stop=5.0, num=10)\n",
    "svr_grid = [\n",
    "    #Grid for rbf and sigmoid kernel\n",
    "    {'C': c_range, 'gamma': gamma_range, 'kernel': ['rbf']},\n",
    "    #Grid for polinomial kernel\n",
    "    {'C': c_range, 'gamma': gamma_range, 'kernel': ['poly'], 'degree': [2,3]}\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating estimators for each learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_methods function will create the empty estimators and map them to their corresponding hyperparameter grid.\n",
    "def get_learning_methods():\n",
    "    learning_methods = [{'name': 'OLS', 'estimator': linear_model.LinearRegression(), 'hyperparameter_grid': least_squares_grid},\n",
    "                        {'name': 'RIDGE','estimator':linear_model.Ridge(random_state=seed), 'hyperparameter_grid': ridge_grid},\n",
    "                        {'name': 'LASSO', 'estimator': linear_model.Lasso(max_iter=100000), 'hyperparameter_grid': lasso_grid},\n",
    "                        {'name': 'PLS', 'estimator': cross_decomposition.PLSRegression(scale=False), 'hyperparameter_grid': pls_grid},\n",
    "                        {'name': 'SVR', 'estimator': svm.SVR(), 'hyperparameter_grid': svr_grid}]#tol=0.01, max_iter=500000\n",
    "    return learning_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(features, target):\n",
    "    \"\"\"\n",
    "    Performs nested cross-validation over the given dataset, for each learning method defined.\n",
    "    \n",
    "    Reports the scores, over both train and test sets, calculated in the outer cross-validation loop.\n",
    "    \n",
    "    Parameters:\n",
    "    features: A numpy array of shape (n_samples, n_features) containing dataset features.\n",
    "    target: A numpy array of shape (n_samples, n_features) containing dataset target variable.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with keys 'test_scores', 'training_scores', containing the scores calculated in the outer cv loop.\n",
    "    \"\"\"\n",
    "    #     \n",
    "    #Score metric used for hyperparameter optimization in inner CV loop\n",
    "    inner_scoring = 'neg_mean_squared_error'\n",
    "    \n",
    "    learning_methods = get_learning_methods()\n",
    "    \n",
    "    results = {}\n",
    "    for learning_method in learning_methods:\n",
    "        \n",
    "        print(\"----\"+ learning_method['name'] + \"------\")\n",
    "        \n",
    "        #Setting a seed ensures that each learning method will be trained on the same splits.\n",
    "        inner_cv = KFold(n_splits=10, shuffle=True, random_state=seed + 1)\n",
    "        outer_cv = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        \n",
    "        #Contains data about the results for a particular learning method.\n",
    "        learning_method_results = {}\n",
    "        \n",
    "        learning_method_results['best_parameters'] = []\n",
    "        learning_method_results['train_scores'] = {'R-Squared': [], 'RMSE': []}\n",
    "        learning_method_results['test_scores'] = {'R-Squared': [], 'RMSE': []}\n",
    "        \n",
    "        #split() method returns a generator that gives all cross-validation partitions. \n",
    "        for train_index, test_index in outer_cv.split(features):\n",
    "            \n",
    "            #Split the data between train and test sets\n",
    "            train_features, test_features = features[train_index], features[test_index]\n",
    "            train_target, test_target = target[train_index], target[test_index]\n",
    "            \n",
    "            \n",
    "            #When the fit() method is called, it will internally perform a grid search cross-validation. \n",
    "            #Once it finds the best hyperparameters, it will fit on complete training set using those parameters.\n",
    "            grid_search_estimator = GridSearchCV(estimator = learning_method['estimator'], \n",
    "                           param_grid = learning_method['hyperparameter_grid'], \n",
    "                           cv = inner_cv, \n",
    "                           scoring = inner_scoring,\n",
    "                           #When n_jobs is -1, all CPUs are used to run cross-validation in parallel\n",
    "                           n_jobs=-1)\n",
    "            \n",
    "            grid_search_estimator.fit(train_features, train_target)\n",
    "            best_parameters = grid_search_estimator.best_params_\n",
    "            learning_method_results['best_parameters'].append(best_parameters)\n",
    "            \n",
    "            #Prediction using the best estimator selected via Grid Search CV\n",
    "            train_prediction = grid_search_estimator.predict(train_features)\n",
    "            test_prediction = grid_search_estimator.predict(test_features)\n",
    "            \n",
    "            \n",
    "            #Calculating R-Squared score\n",
    "            train_r2 = r2_score(y_true = train_target, y_pred = train_prediction)\n",
    "            test_r2 = r2_score(y_true = test_target, y_pred = test_prediction)\n",
    "            \n",
    "            learning_method_results['train_scores']['R-Squared'].append(train_r2)\n",
    "            learning_method_results['test_scores']['R-Squared'].append(test_r2)\n",
    "            \n",
    "            #Calculating RMSE score\n",
    "            train_rmse =  mean_squared_error(y_true = train_target, y_pred = train_prediction, squared=False)\n",
    "            test_rmse = mean_squared_error(y_true = test_target, y_pred = test_prediction, squared=False)\n",
    "            \n",
    "            learning_method_results['train_scores']['RMSE'].append(train_rmse)\n",
    "            learning_method_results['test_scores']['RMSE'].append(test_rmse)\n",
    "            \n",
    "        \n",
    "            \n",
    "        #Stores results for a particular learning method\n",
    "        results[learning_method['name']] = learning_method_results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Receives the results for a specific dataset and transform them into more readeable dataframes\n",
    "def extract_nestedcv_results(results):\n",
    "    \n",
    "    learning_methods_names = ['OLS', 'RIDGE', 'LASSO', 'PLS', 'SVR']\n",
    "    \n",
    "    #Groups test scores of every learning method in one dictionary per metric.\n",
    "    train_r2 = {method_name:results[method_name]['train_scores']['R-Squared'] for method_name in learning_methods_names} \n",
    "    train_rmse = {method_name:results[method_name]['train_scores']['RMSE'] for method_name in learning_methods_names}\n",
    "    \n",
    "    #Groups test scores of every learning method in one dictionary per metric.\n",
    "    test_r2 = {method_name:results[method_name]['test_scores']['R-Squared'] for method_name in learning_methods_names} \n",
    "    test_rmse = {method_name:results[method_name]['test_scores']['RMSE'] for method_name in learning_methods_names}\n",
    "    \n",
    "    \n",
    "    #For each learning algorithm, groups best parameters selected in each iteration of Nested CV outer loop\n",
    "    best_parameters = {method_name:results[method_name]['best_parameters'] for method_name in learning_methods_names}\n",
    "    \n",
    "    return {'train_r2': pd.DataFrame(train_r2), 'train_rmse': pd.DataFrame(train_rmse),\n",
    "           'test_r2': pd.DataFrame(test_r2), 'test_rmse': pd.DataFrame(test_rmse), \n",
    "           'best_parameters': pd.DataFrame(best_parameters)}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More naive approaches to hyperparameter optimization and algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The nested_cv function returns a dictionary like with the outer cross-validation loop scores for every learning method.\n",
    "#The dictionary looks like:\n",
    "#{\n",
    "#    'r2': {'PLS': [0.99,...,0.67], 'SVR': [0.94,..., 0.98], ... , 'OLS': [0.4, ..., 0.32]}, \n",
    "#  'rmse': {'PLS': [1.297116,...,2.297116], 'SVR': [1.291,..., 0.29471], ... , 'OLS': [3.19283, ..., 5.827391]}\n",
    "#}\n",
    "def naive_approach(features, target, k_value = 10):\n",
    "    \n",
    "    #Score metric used for hyperparameter optimization in inner CV loop\n",
    "    inner_scoring = 'neg_root_mean_squared_error'\n",
    "    \n",
    "    #Score metrics used in outer CV loop for generalization performance estimation of the learning method \n",
    "    outer_scoring = ['r2', 'neg_root_mean_squared_error']\n",
    "    \n",
    "    test_r2 = {}\n",
    "    train_r2 = {}\n",
    "    test_rmse = {}\n",
    "    train_rmse = {}\n",
    "    best_hyperparameters = {}\n",
    "    \n",
    "    learning_methods = get_learning_methods()\n",
    "    \n",
    "    for learning_method in learning_methods:\n",
    "        #gridsearch_cv = KFold(n_splits=k_value, shuffle=True, random_state=seed + 1)\n",
    "        #comparison_cv = KFold(n_splits=k_value, shuffle=True, random_state=seed)\n",
    "        \n",
    "        gridsearch_cv = FiveCrossFourKFold(features, seed + 1)\n",
    "        comparison_cv = FiveCrossFourKFold(features, seed)\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator = learning_method['estimator'], \n",
    "                           param_grid = learning_method['hyperparameter_grid'], \n",
    "                           cv = gridsearch_cv, \n",
    "                           scoring = inner_scoring,\n",
    "                           #When n_jobs is -1, all CPUs are used to run cross-validation in parallel\n",
    "                           n_jobs=-1)\n",
    "        \n",
    "        #When the fit() method is called, it will internally perform a grid search cross-validation.\n",
    "        grid_search.fit(features, target)\n",
    "\n",
    "        #The best model/hyperparameters are evaluated on a cross-validation process\n",
    "        cv_results = cross_validate(estimator = grid_search.best_estimator_, \n",
    "                                          X = features, y = target, \n",
    "                                          cv = comparison_cv, scoring = outer_scoring,\n",
    "                                          return_train_score=True)\n",
    "        \n",
    "        test_r2[learning_method['name']] = cv_results['test_r2'].tolist()\n",
    "        train_r2[learning_method['name']] = cv_results['train_r2'].tolist()\n",
    "        \n",
    "        #Inside CV, the RSME score is managed as a negative RMSE. Multiplying it by -1 will turn it into the usual positive RMSE  \n",
    "        test_rmse[learning_method['name']] = (cv_results['test_neg_root_mean_squared_error']*-1).tolist() \n",
    "        train_rmse[learning_method['name']] = (cv_results['train_neg_root_mean_squared_error']*-1).tolist()\n",
    "        \n",
    "        \n",
    "        best_hyperparameters[learning_method['name']] = grid_search.best_params_\n",
    "        \n",
    "        \n",
    "    return {'train_r2': train_r2, 'train_rmse': train_rmse, \n",
    "            'test_r2': test_r2, 'test_rmse':test_rmse, \n",
    "            'best_hyperparameters': best_hyperparameters}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5x2 CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FiveCrossFourKFold(data, seed):\n",
    "    for i in range(5):\n",
    "        kfold = KFold(n_splits=2, shuffle=True, random_state=seed + i)\n",
    "        for train_index, test_index in kfold.split(data):\n",
    "            yield train_index, test_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "    nested_cv_results = {}\n",
    "    k10_results = {}\n",
    "    k5_results = {}\n",
    "    \n",
    "    for dataset in datasets():\n",
    "        print(\"Running experiments in dataset \", dataset['name'])\n",
    "        k5_results[dataset['name']] = naive_approach(dataset['features'], dataset['target'], k_value=5)\n",
    "        nested_cv_results[dataset['name']] =  k5_results[dataset['name']]  #nested_cv(dataset['features'], dataset['target'])\n",
    "        k10_results[dataset['name']] = k5_results[dataset['name']] #naive_approach(dataset['features'], dataset['target'], k_value=10)\n",
    "    \n",
    "    return {'nested_cv': nested_cv_results, '10cv': k10_results, '5cv': k5_results}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments with feature selection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subset_sizes = [60, 50, 40, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Number of Features ; 60---------------------\n",
      "Running experiments in dataset  p1STN\n",
      "Running experiments in dataset  p4LYZ\n",
      "Running experiments in dataset  p1BPI\n",
      "Running experiments in dataset  HLYZ\n",
      "----------------- Number of Features ; 50---------------------\n",
      "Running experiments in dataset  p1STN\n",
      "Running experiments in dataset  p4LYZ\n",
      "Running experiments in dataset  p1BPI\n",
      "Running experiments in dataset  HLYZ\n",
      "----------------- Number of Features ; 40---------------------\n",
      "Running experiments in dataset  p1STN\n",
      "Running experiments in dataset  p4LYZ\n",
      "Running experiments in dataset  p1BPI\n",
      "Running experiments in dataset  HLYZ\n",
      "----------------- Number of Features ; 30---------------------\n",
      "Running experiments in dataset  p1STN\n",
      "Running experiments in dataset  p4LYZ\n",
      "Running experiments in dataset  p1BPI\n",
      "Running experiments in dataset  HLYZ\n"
     ]
    }
   ],
   "source": [
    "for number_of_features in feature_subset_sizes:\n",
    "    print(\"----------------- Number of Features ; \" + str(number_of_features) + \"---------------------\")\n",
    "    results = run_experiments()\n",
    "    \n",
    "#     dump_results(results['nested_cv'], results_dir +str(number_of_features) +'fs_nestedCV.pickle')\n",
    "#     dump_results(results['10cv'], results_dir + str(number_of_features) +'fs_10CV.pickle')\n",
    "    dump_results(results['5cv'], results_dir + str(number_of_features) +'fs_5CV.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(res, label):\n",
    "    for name in [dataset['name'] for dataset in datasets()]:\n",
    "        test_r2 = pd.DataFrame(res[name]['test_r2'])\n",
    "        test_rmse = pd.DataFrame(res[name]['test_rmse'])\n",
    "        display_boxplot(test_r2, \"Dataset \" + name + \" Test R-Squared\" + label)\n",
    "        display_boxplot(test_rmse, \"Dataset \" + name + \" Test RMSE \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_boxplot(df, title):\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add traces\n",
    "    fig.add_trace(go.Box(y=df['RIDGE'], name=\"Ridge\", boxpoints='all'), secondary_y=False)\n",
    "    fig.add_trace(go.Box(y=df['LASSO'], name=\"Lasso\", boxpoints='all'), secondary_y=True)\n",
    "    fig.add_trace(go.Box(y=df['PLS'], name=\"PLS\", boxpoints='all'), secondary_y=True)\n",
    "    fig.add_trace(go.Box(y=df['SVR'], name=\"SVR\", boxpoints='all'), secondary_y=True)\n",
    "    \n",
    "    # Add figure title\n",
    "    fig.update_layout(title_text=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '../../results/modeling/fivefortwo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serializing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dumps a dictionary with the results into a text file so it can be loaded later in Python.\n",
    "def dump_results(results, filename):\n",
    "    with open(filename, 'wb') as results_file:\n",
    "        pickle.dump(results, results_file)\n",
    "\n",
    "    loaded_results = load_dumped_results(filename)\n",
    "\n",
    "    #If the original results and the dumped ones are not the same\n",
    "    if(results != loaded_results):\n",
    "        raise Exception('There was a error. The loaded dumped results are not the same as the original.')\n",
    "        \n",
    "#Loads the dumped results\n",
    "def load_dumped_results(filename):\n",
    "    with open(filename, 'rb') as results_file:\n",
    "        loaded_results = pickle.load(results_file)\n",
    "    return loaded_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities for exporting the results into latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'mean'\n",
    "fivefortwo = load_dumped_results('../../results/modeling/fivefortwo/transformed/pca/_5x2CV.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fivefortwo = load_dumped_results('../../results/modeling/fivefortwo/40fs_5CV.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'mean'\n",
    "nested = load_dumped_results('../../results/modeling/first_experiments/'+ experiment +'_nestedCV.pickle')\n",
    "tencv = load_dumped_results('../../results/modeling/first_experiments/'+ experiment +'_10CV.pickle')\n",
    "fivecv = load_dumped_results('../../results/modeling/first_experiments/'+ experiment +'_5CV.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = str(40)\n",
    "nested = load_dumped_results('../../results/modeling/pearson99/'+ experiment +'fs_nestedCV.pickle')\n",
    "tencv = load_dumped_results('../../results/modeling/pearson99/'+ experiment +'fs_10CV.pickle')\n",
    "fivecv = load_dumped_results('../../results/modeling/pearson99/'+ experiment +'fs_5CV.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1STN : {'C': 1.0, 'epsilon': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
    "#4LYZ: {'C': 10.0, 'epsilon': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
    "#1BPI: {'C': 100.0, 'epsilon': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
    "#HLYZ: {'C': 1000.0, 'epsilon': 1.3, 'gamma': 0.001, 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested = load_dumped_results('../../results/modeling/fivefortwo/40fs_5CV.pickle')\n",
    "tencv = load_dumped_results('../../results/modeling/fivefortwo/40fs_5CV.pickle')\n",
    "fivecv = load_dumped_results('../../results/modeling/fivefortwo/40fs_5CV.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OLS': {},\n",
       " 'RIDGE': {'alpha': 100.0},\n",
       " 'LASSO': {'alpha': 0.1},\n",
       " 'PLS': {'n_components': 2},\n",
       " 'SVR': {'C': 100.0, 'epsilon': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fivecv['p1BPI']['best_hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1STN {'C': 10.0, 'epsilon': 1.3, 'gamma': 0.01, 'kernel': 'rbf'}\n",
    "#4LYZ {'C': 10.0, 'epsilon': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}}\n",
    "#1BPI {'C': 100.0, 'epsilon': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Nested Results-----------------------\n",
      "\\begin{tabular}{lrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  score1mean &  score1median &  score1stdev &  score1max &  score1min &  score2mean &  score2median &  score2stdev &  score2max &  score2min \\\\\n",
      "\\midrule\n",
      "OLS   &        0.12 &          0.20 &         0.33 &       0.50 &      -0.51 &        3.98 &          3.53 &         0.92 &       5.53 &       3.06 \\\\\n",
      "RIDGE &        0.23 &          0.29 &         0.27 &       0.51 &      -0.17 &        3.73 &          3.46 &         0.81 &       4.85 &       2.44 \\\\\n",
      "LASSO &        0.18 &          0.32 &         0.44 &       0.64 &      -0.56 &        3.75 &          3.82 &         0.92 &       5.43 &       2.42 \\\\\n",
      "PLS   &        0.19 &          0.22 &         0.27 &       0.56 &      -0.30 &        3.85 &          3.68 &         1.01 &       5.97 &       2.60 \\\\\n",
      "SVR   &        0.42 &          0.47 &         0.27 &       0.76 &      -0.06 &        3.13 &          3.16 &         0.43 &       3.98 &       2.56 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "---------------------- 10Fold Results-----------------------\n",
      "\\begin{tabular}{lrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  score1mean &  score1median &  score1stdev &  score1max &  score1min &  score2mean &  score2median &  score2stdev &  score2max &  score2min \\\\\n",
      "\\midrule\n",
      "OLS   &        0.12 &          0.20 &         0.33 &       0.50 &      -0.51 &        3.98 &          3.53 &         0.92 &       5.53 &       3.06 \\\\\n",
      "RIDGE &        0.26 &          0.29 &         0.30 &       0.66 &      -0.17 &        3.61 &          3.46 &         0.75 &       4.68 &       2.44 \\\\\n",
      "LASSO &        0.25 &          0.30 &         0.29 &       0.64 &      -0.15 &        3.63 &          3.45 &         0.74 &       4.75 &       2.62 \\\\\n",
      "PLS   &        0.24 &          0.27 &         0.33 &       0.70 &      -0.39 &        3.61 &          3.74 &         0.67 &       4.71 &       2.64 \\\\\n",
      "SVR   &        0.47 &          0.48 &         0.25 &       0.78 &      -0.06 &        2.98 &          3.02 &         0.37 &       3.59 &       2.43 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "---------------------- 5Fold Results-----------------------\n",
      "\\begin{tabular}{lrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  score1mean &  score1median &  score1stdev &  score1max &  score1min &  score2mean &  score2median &  score2stdev &  score2max &  score2min \\\\\n",
      "\\midrule\n",
      "OLS   &        0.11 &         -0.03 &         0.23 &       0.40 &      -0.08 &        4.24 &          4.11 &         0.55 &       4.90 &       3.49 \\\\\n",
      "RIDGE &        0.28 &          0.24 &         0.12 &       0.42 &       0.13 &        3.84 &          3.92 &         0.52 &       4.42 &       2.99 \\\\\n",
      "LASSO &        0.28 &          0.20 &         0.16 &       0.46 &       0.13 &        3.83 &          3.87 &         0.45 &       4.41 &       3.18 \\\\\n",
      "PLS   &        0.29 &          0.33 &         0.24 &       0.60 &      -0.05 &        3.73 &          3.75 &         0.32 &       4.07 &       3.30 \\\\\n",
      "SVR   &        0.48 &          0.49 &         0.13 &       0.67 &       0.35 &        3.25 &          3.13 &         0.50 &       3.80 &       2.72 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results(nested, tencv, fivecv, 'HLYZ', test=True, to_latex=True, info='scores_summary') #scores_summary, iteration_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If test=false Returns train scores instead of test scores. If to_latex is False, then it returns the dataframes with\n",
    "#the results. \n",
    "#info can take the values 'iteration_scores','scores_summary', 'both'.\n",
    "def show_results(nested_results, tenfold_results, fivefold_results, dataset_name, test=True, to_latex=True, info='scores_summary'):\n",
    "    \"\"\"\n",
    "    params: \n",
    "        nested_results: Results returned by the nested_cv function.\n",
    "        tenfold_results: Results returned by naive_approach function with k=10\n",
    "        fivefold_results Results returned by naive_approach function with k=5\n",
    "        dataset_name: A string with the name of the dataset which results are needed. Possible values are 'p1STN', 'p4LYZ', 'p1BPI', 'HLYZ'.\n",
    "        test: A boolean value. If True, then it returns the test scores. If False, then it return train scores.\n",
    "        to_latex: A boolean value. If True, it prints the results as latex-formatted tables. If False, results are displayed as Pandas DataFrames.\n",
    "        info: A string that indicates what kind of information it is needed. 'scores_summary', \n",
    "        mean, median, stdev, max and min statistics are showed. If it is 'iteration_scores', then individual scores for each cross-validation iteration are showed.\n",
    "        If 'both', then function shows both individual scores and summary statistics.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if(test):\n",
    "        score_prefix = 'test_'\n",
    "    else:\n",
    "        score_prefix = 'train_'\n",
    "    \n",
    "    nested_results = nested_results[dataset_name]\n",
    "    tenfold_results = tenfold_results[dataset_name]\n",
    "    fivefold_results = fivefold_results[dataset_name]\n",
    "    \n",
    "    \n",
    "    #Getting test scores \n",
    "    nested_r2, tenfold_r2, fivefold_r2 = algo(nested_results, tenfold_results, \n",
    "                                             fivefold_results, score=score_prefix + 'r2', \n",
    "                                             info=info)\n",
    "    \n",
    "    \n",
    "    nested_rmse, tenfold_rsme, fivefold_rmse = algo(nested_results, tenfold_results, \n",
    "                                                    fivefold_results, score=score_prefix + 'rmse',\n",
    "                                                    info=info)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(info=='scores_summary'):\n",
    "    \n",
    "        nested_df = concat_scores_statistics(nested_r2, nested_rmse)\n",
    "        tenfold_df = concat_scores_statistics(tenfold_r2, tenfold_rsme)\n",
    "        fivefold_df = concat_scores_statistics(fivefold_r2, fivefold_rmse)\n",
    "    \n",
    "        if(to_latex):\n",
    "            print('---------------------- Nested Results-----------------------')\n",
    "            export_to_latex(nested_df)\n",
    "            print('---------------------- 10Fold Results-----------------------')\n",
    "            export_to_latex(tenfold_df)\n",
    "            print('---------------------- 5Fold Results-----------------------')\n",
    "            export_to_latex(fivefold_df)\n",
    "        else:\n",
    "            print('---------------------- Nested Results-----------------------')\n",
    "            display(nested_df)\n",
    "            print('---------------------- 10Fold Results-----------------------')\n",
    "            display(tenfold_df)\n",
    "            print('---------------------- 5Fold Results-----------------------')\n",
    "            display(fivefold_df)\n",
    "    else: \n",
    "        \n",
    "        if(to_latex):\n",
    "            print('---------------------- Nested Results-----------------------')\n",
    "            print('-----R2 -----')\n",
    "            export_to_latex(nested_r2)\n",
    "            print('-----RMSE -----')\n",
    "            export_to_latex(nested_rmse)\n",
    "            print('---------------------- 10Fold Results-----------------------')\n",
    "            print('-----R2 -----')\n",
    "            export_to_latex(tenfold_r2)\n",
    "            print('-----RMSE -----')\n",
    "            export_to_latex(tenfold_rsme)\n",
    "            print('---------------------- 5Fold Results-----------------------')\n",
    "            print('-----R2 -----')\n",
    "            export_to_latex(fivefold_r2)\n",
    "            print('-----RMSE -----')\n",
    "            export_to_latex(fivefold_rmse)\n",
    "        else: \n",
    "            print('---------------------- Nested Results-----------------------')\n",
    "            print('-----R2 -----')\n",
    "            display(nested_r2)\n",
    "            print('-----RMSE -----')\n",
    "            display(nested_rmse)\n",
    "            print('---------------------- 10Fold Results-----------------------')\n",
    "            print('-----R2 -----')\n",
    "            display(tenfold_r2)\n",
    "            print('-----RMSE -----')\n",
    "            display(tenfold_rsme)\n",
    "            print('---------------------- 5Fold Results-----------------------')\n",
    "            print('-----R2 -----')\n",
    "            display(fivefold_r2)\n",
    "            print('-----RMSE -----')\n",
    "            display(fivefold_rmse)\n",
    "            \n",
    "            \n",
    "#Returns dataframes with the statistics for each validation procedure\n",
    "def algo(nested_results, tenfold_results, fivefold_results, score, info):\n",
    "    \n",
    "    nested = preprocess_results(extract_nestedcv_results(nested_results)[score])\n",
    "    tenfold = preprocess_results(pd.DataFrame(tenfold_results[score]))\n",
    "    fivefold = preprocess_results(pd.DataFrame(fivefold_results[score]))\n",
    "    \n",
    "    if(info == 'iteration_scores'):\n",
    "        nested = nested.iloc[:, 5:]\n",
    "        tenfold = tenfold.iloc[:, 5:]\n",
    "        fivefold = fivefold.iloc[:, 5:]\n",
    "    if(info == 'scores_summary'):\n",
    "        nested = nested.iloc[:,:5]\n",
    "        tenfold = tenfold.iloc[:,:5]\n",
    "        fivefold = fivefold.iloc[:,:5]\n",
    "        \n",
    "    return nested, tenfold, fivefold\n",
    "\n",
    "#Returns a dataframe with the scores concatenated. Used for merge statistics from R2 and RMSE\n",
    "#into the same dataframe.\n",
    "def concat_scores_statistics(score1, score2):\n",
    "    #A different  prefix is added to the columns names of each dataframe so they have no conflicts.\n",
    "    return pd.concat([add_prefix_to_columns(score1, \"score1\"), add_prefix_to_columns(score2, \"score2\")],axis=1)\n",
    "\n",
    "#Used to add a prefix to the column names. \n",
    "def add_prefix_to_columns(df, prefix):\n",
    "    return df.rename(columns={column: prefix + column for column in df.columns.to_list()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess results before exporting them. Include the calculation of statistics and rounding.\n",
    "def preprocess_results(results):\n",
    "    results = calculate_statistics(results).round(decimals=2)\n",
    "    return results\n",
    "\n",
    "\n",
    "#This function calculates statistics (mean, median, stdev, max and min)\n",
    "#based on the results. Returns a transposed dataframe with the statistics appended to it\n",
    "def calculate_statistics(df):\n",
    "    r = df.T\n",
    "    r = r.rename(columns = {column:'I' + str(column + 1) for column in r.columns.tolist()})\n",
    "    \n",
    "    \n",
    "    r.insert(loc=0, column='min', value= df.T.min(axis='columns'))\n",
    "    r.insert(loc=0, column='max', value= df.T.max(axis='columns'))\n",
    "    r.insert(loc=0, column='stdev', value= df.T.std(axis='columns'))\n",
    "    r.insert(loc=0, column='median', value=df.T.median(axis='columns'))\n",
    "    r.insert(loc=0, column='mean', value= df.T.mean(axis='columns'))\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_latex(results):\n",
    "    print(results.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting results to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_excel(results, experiment_name):\n",
    "    file_name = results_dir + experiment_name + '.xlsx'\n",
    "    with pd.ExcelWriter(file_name) as writer:\n",
    "        \n",
    "        for dataset_name in results.keys():\n",
    "            dataset_results = results[dataset_name]\n",
    "            \n",
    "            for metric_name in dataset_results.keys():\n",
    "                sheet_name = dataset_name + \"_\" + metric_name\n",
    "                process_results(pd.DataFrame(dataset_results[metric_name])).to_excel(writer, sheet_name = sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"fs_48Pearson\"\n",
    "export_to_excel(results, \"10FCV_\" + experiment_name)\n",
    "export_to_excel(k5_results, \"5FCV_\" + experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=20000,oob_score=True,max_features=\"sqrt\",n_jobs=-1, bootstrap=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors eliminated: -2\n",
      "p1STN 0.3046317555086936\n",
      "Descriptors eliminated: -2\n",
      "p4LYZ 0.0929459146633369\n",
      "Descriptors eliminated: -2\n",
      "p1BPI 0.6456264335249176\n",
      "Descriptors eliminated: -2\n",
      "HLYZ 0.3836228452043532\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets():\n",
    "    rf.fit(dataset['features'], dataset['target'])\n",
    "    print(dataset['name'], rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembles of SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "HLYZ = pd.read_csv('../../data/processed/original/HLYZ.csv')\n",
    "preprocessed_HLYZ = preprocess_dataset(HLYZ)\n",
    "features, target = separate_features_and_target(preprocessed_HLYZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=9, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'C': array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
       "       1.e+02, 1.e+03, 1.e+04...\n",
       "       1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06]),\n",
       "                          'degree': [2, 3],\n",
       "                          'epsilon': array([1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2,\n",
       "       2.3, 2.4, 2.5]),\n",
       "                          'gamma': array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,\n",
       "       1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06]),\n",
       "                          'kernel': ['poly']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_root_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = GridSearchCV(estimator = svm.SVR(), \n",
    "                           param_grid = svr_grid, \n",
    "                           cv = KFold(n_splits=5, shuffle=True, random_state=9), \n",
    "                           scoring = 'neg_root_mean_squared_error',\n",
    "                           #When n_jobs is -1, all CPUs are used to run cross-validation in parallel\n",
    "                           n_jobs=-1)\n",
    "\n",
    "est.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaggingRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-552ce2f15b4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m bag_reg = BaggingRegressor(est.best_estimator_,\n\u001b[0m\u001b[0;32m      2\u001b[0m                           \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                           bootstrap=True, oob_score=True)\n\u001b[0;32m      4\u001b[0m \u001b[0mbag_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BaggingRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "bag_reg = BaggingRegressor(est.best_estimator_,\n",
    "                          n_estimators=50, max_samples = len(features), n_jobs=-1,\n",
    "                          bootstrap=True, oob_score=True)\n",
    "bag_reg.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_reg.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing nested cross-validation on research datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets_dir = '../../data/test_datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boston housing\n",
    "boston_X, boston_y = load_boston(return_X_y=True)\n",
    "\n",
    "#Diabetes\n",
    "diabetes_X, diabetes_y = load_diabetes(return_X_y=True)\n",
    "\n",
    "#California\n",
    "california_X, california_y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "#Fish\n",
    "fish = pd.read_csv(test_datasets_dir + 'Fish.csv')\n",
    "fish_X, fish_y = fish.iloc[:,2:len(fish.columns)].to_numpy(), fish.iloc[:, 1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "boston_sample = np.random.choice(len(boston_y), 60, replace=False)\n",
    "diabetes_sample = np.random.choice(len(diabetes_y), 60, replace=False)\n",
    "california_sample = np.random.choice(len(california_y), 60, replace=False)\n",
    "fish_sample = np.random.choice(len(fish), 60, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "california_sample = np.random.choice(len(california_y), 400, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)  # 1 line, 2 rows, index nr 1 (first position in the subplot)\n",
    "plt.hist(boston_y[boston_sample])\n",
    "plt.subplot(1, 2, 2)  # 1 line, 2 rows, index nr 2 (second position in the subplot)\n",
    "plt.hist(boston_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)  # 1 line, 2 rows, index nr 1 (first position in the subplot)\n",
    "plt.hist(diabetes_y[diabetes_sample])\n",
    "plt.subplot(1, 2, 2)  # 1 line, 2 rows, index nr 2 (second position in the subplot)\n",
    "plt.hist(diabetes_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)  # 1 line, 2 rows, index nr 1 (first position in the subplot)\n",
    "plt.hist(california_y[california_sample])\n",
    "plt.subplot(1, 2, 2)  # 1 line, 2 rows, index nr 2 (second position in the subplot)\n",
    "plt.hist(california_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boston_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-da674aaba6bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mboston_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboston_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboston_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mboston_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboston_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mboston_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdiabetes_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiabetes_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiabetes_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdiabetes_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiabetes_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdiabetes_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcalifornia_X\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcalifornia_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalifornia_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcalifornia_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcalifornia_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcalifornia_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfish_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfish_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfish_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfish_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfish_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'boston_sample' is not defined"
     ]
    }
   ],
   "source": [
    "boston_X, boston_y = scale(boston_X[boston_sample]), boston_y[boston_sample]\n",
    "diabetes_X, diabetes_y = scale(diabetes_X[diabetes_sample]), diabetes_y[diabetes_sample]\n",
    "california_X , california_y = scale(california_X[california_sample]), california_y[california_sample]\n",
    "fish_X, fish_y = scale(fish_X[fish_sample]), fish_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_X = scale(boston_X)\n",
    "diabetes_X = scale(diabetes_X)\n",
    "california_X , california_y = scale(california_X[california_sample]), california_y[california_sample]\n",
    "fish_X = scale(fish_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exps(features, target, name):\n",
    "    dump_results(nested_cv(features, target), results_dir + name +'_nestedCV.pickle')\n",
    "    dump_results(naive_approach(features, target, k_value=5), results_dir + name +'_10CV.pickle')\n",
    "    dump_results(naive_approach(features, target, k_value=10), results_dir + name +'_5CV.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps(boston_X,boston_y, 'boston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps(diabetes_X,diabetes_y, 'diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exps(california_X,california_y, 'california')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----OLS------\n",
      "----RIDGE------\n",
      "----LASSO------\n",
      "----PLS------\n",
      "----SVR------\n"
     ]
    }
   ],
   "source": [
    "exps(fish_X,fish_y, 'fish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing research datasets results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_results = load_dumped_results('../../results/modeling/research_datasets/diabetes_nestedCV.pickle')\n",
    "boston_results = extract_nestedcv_results(boston_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS</th>\n",
       "      <th>RIDGE</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>PLS</th>\n",
       "      <th>SVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.831610</td>\n",
       "      <td>-0.816851</td>\n",
       "      <td>-0.696686</td>\n",
       "      <td>-1.094875</td>\n",
       "      <td>-0.964619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.150077</td>\n",
       "      <td>-0.070626</td>\n",
       "      <td>-0.043684</td>\n",
       "      <td>0.085782</td>\n",
       "      <td>-0.134195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.234064</td>\n",
       "      <td>0.333155</td>\n",
       "      <td>0.187814</td>\n",
       "      <td>0.307392</td>\n",
       "      <td>0.356545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.067704</td>\n",
       "      <td>-0.035376</td>\n",
       "      <td>0.086306</td>\n",
       "      <td>-0.192228</td>\n",
       "      <td>-1.236976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.508925</td>\n",
       "      <td>-0.015675</td>\n",
       "      <td>0.160921</td>\n",
       "      <td>-0.272310</td>\n",
       "      <td>-0.024799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.207676</td>\n",
       "      <td>0.482278</td>\n",
       "      <td>0.334519</td>\n",
       "      <td>0.493971</td>\n",
       "      <td>0.548504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.460419</td>\n",
       "      <td>0.459261</td>\n",
       "      <td>0.449243</td>\n",
       "      <td>0.530806</td>\n",
       "      <td>0.501201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.636812</td>\n",
       "      <td>-0.665636</td>\n",
       "      <td>-0.702651</td>\n",
       "      <td>-0.769241</td>\n",
       "      <td>-0.112754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.012135</td>\n",
       "      <td>0.099744</td>\n",
       "      <td>0.026155</td>\n",
       "      <td>-0.020585</td>\n",
       "      <td>0.018237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.433217</td>\n",
       "      <td>0.417408</td>\n",
       "      <td>0.312093</td>\n",
       "      <td>0.518336</td>\n",
       "      <td>0.471164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OLS     RIDGE     LASSO       PLS       SVR\n",
       "0 -0.831610 -0.816851 -0.696686 -1.094875 -0.964619\n",
       "1 -0.150077 -0.070626 -0.043684  0.085782 -0.134195\n",
       "2  0.234064  0.333155  0.187814  0.307392  0.356545\n",
       "3 -0.067704 -0.035376  0.086306 -0.192228 -1.236976\n",
       "4 -0.508925 -0.015675  0.160921 -0.272310 -0.024799\n",
       "5  0.207676  0.482278  0.334519  0.493971  0.548504\n",
       "6  0.460419  0.459261  0.449243  0.530806  0.501201\n",
       "7 -0.636812 -0.665636 -0.702651 -0.769241 -0.112754\n",
       "8  0.012135  0.099744  0.026155 -0.020585  0.018237\n",
       "9  0.433217  0.417408  0.312093  0.518336  0.471164"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_results['test_r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
