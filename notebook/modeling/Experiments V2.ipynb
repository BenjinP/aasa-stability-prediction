{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_validate\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_decomposition\n",
    "import plotly.express as px "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results['r2'])\n",
    "    results_df.to_latex(buf='./RSquared_r2_scores_' + dataset['name'] + '.txt', index_names= False,\n",
    "                            caption=\"RSquared scores for dataset\" + dataset['name'])\n",
    "    \n",
    "    results_df = pd.DataFrame(results['rmse'])\n",
    "    results_df.to_latex(buf='./RSquared_rmse_scores_' + dataset['name'] + '.txt', index_names=False,\n",
    "                            caption=\"RMSE scores for dataset\" + dataset['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training and validationdata_url =  \"https://raw.githubusercontent.com/Naio/aasa-stability-prediction/master/data/processed/\"\n",
    "#Seed for controlling any random procedure during the experiments\n",
    "seed = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining hyperparameter grids\n",
    "Each algorithm has its corresponding hyperparameter grid for later use in grid search inner cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares_grid = {} #Ordinary least square doesn't have hyperparamters\n",
    "\n",
    "ridge_grid = {'alpha' : np.logspace(-6, 6, 13)} #Alpha between 1.e-06 and 1.e+06\n",
    "lasso_grid = {'alpha' : np.logspace(-6, 6, 13)} \n",
    "pls_grid = {'n_components': np.linspace(start = 2, stop=25, num=24).astype(int)} #Between 2 and 25 Principal Components\n",
    "\n",
    "svr_grid = [\n",
    "    #Grid for linear kernel\n",
    "    {'C': np.logspace(-6, 6, 13), 'kernel': ['linear']},\n",
    "    #Grid for rbf and sigmoid kernel\n",
    "    {'C': np.logspace(-6, 6, 13), 'gamma': np.logspace(-6, 6, 13), 'kernel': ['rbf', 'sigmoid']},\n",
    "    #Grid for polinomial kernel\n",
    "    {'C': np.logspace(-6, 6, 13), 'gamma': np.logspace(-6, 6, 13), 'kernel': ['poly'], 'degree': [2,3,4]}\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating estimators for each learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_methods function will create the empty estimators and map them to their corresponding hyperparameter grid.\n",
    "def get_learning_methods():\n",
    "    learning_methods = [{'name': 'OLS', 'estimator': linear_model.LinearRegression(), 'hyperparameter_grid': least_squares_grid},\n",
    "                        {'name': 'RIDGE','estimator':linear_model.Ridge(random_state=seed), 'hyperparameter_grid': ridge_grid},\n",
    "                        {'name': 'LASSO', 'estimator':linear_model.Lasso(), 'hyperparameter_grid': lasso_grid},\n",
    "                        {'name': 'PLS', 'estimator':cross_decomposition.PLSRegression(), 'hyperparameter_grid': pls_grid},\n",
    "                        {'name': 'SVR', 'estimator':svm.SVR(), 'hyperparameter_grid': svr_grid}]\n",
    "    return learning_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets():\n",
    "    \n",
    "    datasets_names = ['A', 'B', 'C', 'D']\n",
    "    \n",
    "    for dataset_name in datasets_names:\n",
    "        protein_dataset = pd.read_csv(data_url + dataset_name + '.csv')\n",
    "        proteins_X = protein_dataset.iloc[:, 1:].to_numpy()\n",
    "        proteins_X = preprocessing.scale(proteins_X) #Z-Score standarization\n",
    "        proteins_y = protein_dataset.iloc[:,0].to_numpy()\n",
    "        \n",
    "        yield {'name': dataset_name, 'features': proteins_X, 'target': proteins_y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The nested_cv function returns a dictionary like with the outer cross-validation loop scores for every learning method.\n",
    "#The dictionary looks like:\n",
    "#{\n",
    "#    'r2': {'PLS': [0.99,...,0.67], 'SVR': [0.94,..., 0.98], ... , 'OLS': [0.4, ..., 0.32]}, \n",
    "#  'rmse': {'PLS': [1.297116,...,2.297116], 'SVR': [1.291,..., 0.29471], ... , 'OLS': [3.19283, ..., 5.827391]}\n",
    "#}\n",
    "def nested_cv(features, target):\n",
    "    \n",
    "    #Score metric used for hyperparameter optimization in inner CV loop\n",
    "    inner_scoring = 'r2'\n",
    "    \n",
    "    #Score metrics used in outer CV loop for generalization performance estimation of the learning method \n",
    "    outer_scoring = ['r2', 'neg_root_mean_squared_error']\n",
    "    \n",
    "    outer_scores_r2 = {}\n",
    "    outer_scores_rmse = {}\n",
    "    \n",
    "    learning_methods = get_learning_methods()\n",
    "    \n",
    "    for learning_method in learning_methods:\n",
    "        inner_cv = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        outer_cv = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "        #Inner CV estimator\n",
    "        #When the fit() method is called, it will internally perform a grid search cross-validation. \n",
    "        #Once it finds the best hyperparameters, it will fit on complete training set using those parameters.\n",
    "        est = GridSearchCV(estimator = learning_method['estimator'], \n",
    "                           param_grid = learning_method['hyperparameter_grid'], \n",
    "                           cv = inner_cv, \n",
    "                           scoring = inner_scoring,\n",
    "                           #When n_jobs is -1, all CPUs are used to run cross-validation in parallel\n",
    "                           n_jobs=-1)\n",
    "        \n",
    "        for train_index, test_index in outer_cv.split(features):\n",
    "            print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            features_train, features_test = features[train_index], features[test_index]\n",
    "            target_train, target_test = target[train_index], target[test_index]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #For each train-test dataset split in the outer cross validation loop, \n",
    "        #cross_validate function will call the fit() method of the GridSearchCV estimator\n",
    "        #to fit it on the train set. Once the estimator is fitted, it is used to predict over the test set\n",
    "        #and calculate the score.\n",
    "        outer_cv_results = cross_validate(estimator = est, \n",
    "                                          X = features, y = target, \n",
    "                                          cv = outer_cv, scoring = outer_scoring)\n",
    "        \n",
    "        outer_scores_r2[learning_method['name']] = outer_cv_results['test_r2']\n",
    "        \n",
    "        #Inside CV, the RSME score is managed as a negative RMSE. Multiplying it by -1 will turn it into the usual positive RMSE  \n",
    "        outer_scores_rmse[learning_method['name']] = outer_cv_results['test_neg_root_mean_squared_error']*-1 \n",
    "       \n",
    "    return {'r2': outer_scores_r2, 'rmse':outer_scores_rmse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
