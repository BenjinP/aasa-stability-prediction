{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all related to predictive modeling and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methodology used is an adaptation of Crisp-DM. Currently, we are the steps Modeling and Evaluation:\n",
    "1. Domain Understanding\n",
    "2. Data Understanding\n",
    "4. Data Preparation\n",
    "5. **Modeling**\n",
    "6. **Evaluation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_validate\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "from skrebate import SURF\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_url =  \"https://raw.githubusercontent.com/Naio/aasa-stability-prediction/master/data/processed/\"\n",
    "seed = 10 #Seed for controlling any random procedure during the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator that yields ready-to-use (preprocessed) protein datasets.\n",
    "#Each dataset is a dictionary like {'dataset_name': protein_name,\n",
    "#                                    'features': numpy array with dimensions (examples x features),\n",
    "#                                    'target': numpy array with dimensions (examples,)}\n",
    "def datasets():\n",
    "    datasets_names = ['p1STN', 'p4LYZ', 'p1BPI', 'HLYZ']\n",
    "    data_url = 'https://raw.githubusercontent.com/Naio/aasa-stability-prediction/master/data/processed/original/'\n",
    "    \n",
    "    for dataset_name in datasets_names:\n",
    "        #Loads the dataset into a dataframe\n",
    "        protein_dataset = pd.read_csv(data_url + dataset_name + '.csv')\n",
    "        \n",
    "        #Preprocess the dataset (dimensionality reduction, normalization)\n",
    "        protein_dataset = preprocess_dataset(protein_dataset)\n",
    "        \n",
    "        #Sets target aside from features.\n",
    "        features, target = split_features_and_target(protein_dataset)\n",
    "        \n",
    "        yield {'name': dataset_name, 'features': features, 'target': target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Method that performs dataset preprocessing tasks, particularly dimensionality reduction and normalization.\n",
    "# Returns a dataframe with data preprocessed.\n",
    "def preprocess_dataset(df):\n",
    "    \n",
    "    #Discard of those descriptors that are highly correlated\n",
    "    df = discard_highly_correlated_descriptors(df)\n",
    "    \n",
    "    #Feature selection\n",
    "    #Note: This implementation is able to work even if data is not normalized.\n",
    "    df = select_subset_of_features_SURF(df, 40)\n",
    "    \n",
    "    #Z-Score Normalization\n",
    "    df = normalize_data(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discards descriptors that are highly correlated at least with one other descriptor.\n",
    "#The threshold is an absolute Pearson's r greater than 0.99\n",
    "#Returns the dataframe that is passed as a parameter, but without the discarded descriptors.\n",
    "def discard_highly_correlated_descriptors(df):\n",
    "    \n",
    "    #Calculates the absolute Pearson's r correlation matrix. Both -1 and 1 are highly correlated.\n",
    "    correlations = df.corr().abs()\n",
    "    \n",
    "    #Gets the correlation matrix upper triangular.\n",
    "    upper_corr = correlations.where(np.triu(np.ones(correlations.shape), k=1).astype(np.bool))\n",
    "    \n",
    "    #Discards the descriptors\n",
    "    to_drop = [column for column in upper_corr.columns if any(upper_corr[column] > 0.99)]\n",
    "    return df.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A dataframe containing protein data is passed as argument to df.\n",
    "#It returns the dataframe, but containing only the 40 most relevant descriptors selected by SURF algorithm.\n",
    "def select_subset_of_features_SURF(df, n_features):\n",
    "    features_importance = calculate_features_importance(df, n_features)\n",
    "    selected_features = select_n_most_important_features(features_importance, n_features)\n",
    "    filtered_df = filter_selected_columns(df, selected_features)\n",
    "    return filtered_df\n",
    "\n",
    "#Returns a dataframe mapping each descriptor to its importance (a number) given by the SURF algorithm.\n",
    "def calculate_features_importance(df, n_features):\n",
    "    features, target = split_features_and_target(df)\n",
    "    rlf = SURF(n_features_to_select=n_features)\n",
    "    rlf.fit(features, target)\n",
    "    \n",
    "    return pd.DataFrame({'feature_name':df.iloc[:, 2:].columns, \n",
    "                         'importance': rlf.feature_importances_})\n",
    "\n",
    "#The output of the calculate_features_importance methods is passed as an argument to this method.\n",
    "#Based on features_importance, it selects the most importante n_features.\n",
    "#Returns a list with the most important descriptors.\n",
    "def select_n_most_important_features(features_importance, n_features):\n",
    "    return features_importance.sort_values(by='importance', ascending=False).head(n_features)['feature_name'].tolist()\n",
    "\n",
    "#It receives as an argument the dataframe containing the protein data and a list of most relevant descriptors to be selected.\n",
    "#Returns the dataframe containing the most relevant descriptors.\n",
    "def filter_selected_columns(df, columns):\n",
    "    selected = ['id', 'stability']\n",
    "    selected.extend(columns)\n",
    "    return df[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a dataset with normalized descriptors using Z-Score\n",
    "def normalize_data(df):\n",
    "    \n",
    "    #Only descriptores are normalized, so we set apart the stability and mutation name attributes from the original dataset\n",
    "    mutation_stability = df.iloc[:, 0:2]\n",
    "    \n",
    "    \n",
    "    #Setting apart the descriptors data\n",
    "    descriptors = df.iloc[:, 2:]\n",
    "                      \n",
    "    #Normalizing the descriptors using Z-Score\n",
    "    normalized_descriptors = pd.DataFrame(scale(descriptors), columns=descriptors.columns)\n",
    "    \n",
    "    #Joining stability and mutation name to the normalized descriptors\n",
    "    normalized_data = mutation_stability.join(normalized_descriptors)\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns descriptors and target values as numpy arrays\n",
    "def split_features_and_target(df):\n",
    "    features = df.iloc[:, 2:].to_numpy()\n",
    "    target =  df.iloc[:,1].to_numpy()\n",
    "    #target = df['stability'].to_numpy()\n",
    "    #features = df.iloc[:,:len(df.columns) - 1].to_numpy()\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining hyperparameter grids\n",
    "Each algorithm has its corresponding hyperparameter grid for later use in grid search inner cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares_grid = {} #Ordinary least square doesn't have hyperparamters\n",
    "\n",
    "alpha_range = np.logspace(-6, 6, 13)\n",
    "ridge_grid = {'alpha' : alpha_range} #Alpha between 1.e-06 and 1.e+06\n",
    "lasso_grid = {'alpha' : alpha_range} \n",
    "\n",
    "pls_grid = {'n_components': np.linspace(start = 2, stop=25, num=24).astype(int)} #Between 2 and 25 Principal Components\n",
    "c_range = np.logspace(-6, 6, 13) #Between 1.e-05 and 1.e+02. Lower C, more regularization. np.logspace(-3, 3, 7)\n",
    "gamma_range = np.logspace(-6, 6, 13)\n",
    "epsilon_range = np.linspace(start = 1.0, stop=2.5, num=16)\n",
    "svr_grid = [\n",
    "    #Grid for rbf and sigmoid kernel\n",
    "    {'C': c_range, 'gamma': gamma_range, 'kernel': ['rbf'], 'epsilon': epsilon_range},\n",
    "    #Grid for polinomial kernel\n",
    "    {'C': c_range, 'gamma': gamma_range, 'kernel': ['poly'], 'degree': [2,3], 'epsilon': epsilon_range}\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating estimators for each learning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_methods function will create the empty estimators and map them to their corresponding hyperparameter grid.\n",
    "def get_learning_methods():\n",
    "    learning_methods = [{'name': 'OLS', 'estimator': linear_model.LinearRegression(), 'hyperparameter_grid': least_squares_grid},\n",
    "                        {'name': 'RIDGE','estimator':linear_model.Ridge(random_state=seed), 'hyperparameter_grid': ridge_grid},\n",
    "                        {'name': 'LASSO', 'estimator': linear_model.Lasso(max_iter=100000), 'hyperparameter_grid': lasso_grid},\n",
    "                        {'name': 'PLS', 'estimator': cross_decomposition.PLSRegression(scale=False), 'hyperparameter_grid': pls_grid},\n",
    "                        {'name': 'SVR', 'estimator': svm.SVR(), 'hyperparameter_grid': svr_grid}]#tol=0.01, max_iter=500000\n",
    "    return learning_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(features, target):\n",
    "    \"\"\"\n",
    "    Performs nested cross-validation over the given dataset, for each learning method defined.\n",
    "    \n",
    "    Reports the scores, over both train and test sets, calculated in the outer cross-validation loop.\n",
    "    \n",
    "    Parameters:\n",
    "    features: A numpy array of shape (n_samples, n_features) containing dataset features.\n",
    "    target: A numpy array of shape (n_samples, n_features) containing dataset target variable.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with keys 'test_scores', 'training_scores', containing the scores calculated in the outer cv loop.\n",
    "    \"\"\"\n",
    "    #     \n",
    "    #Score metric used for hyperparameter optimization in inner CV loop\n",
    "    inner_scoring = 'neg_mean_squared_error'\n",
    "    \n",
    "    learning_methods = get_learning_methods()\n",
    "    \n",
    "    results = {}\n",
    "    for learning_method in learning_methods:\n",
    "        \n",
    "        print(\"Modeling using\", learning_method['name'],\"method...\")\n",
    "        \n",
    "        #Setting a seed ensures that each learning method will be trained on the same splits.\n",
    "        inner_cv = KFold(n_splits=10, shuffle=True, random_state=seed + 1)\n",
    "        outer_cv = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        \n",
    "        #Contains data about the results for a particular learning method.\n",
    "        learning_method_results = {}\n",
    "        \n",
    "        learning_method_results['best_parameters'] = []\n",
    "        learning_method_results['train_scores'] = {'R-Squared': [], 'RMSE': []}\n",
    "        learning_method_results['test_scores'] = {'R-Squared': [], 'RMSE': []}\n",
    "        \n",
    "        #split() method returns a generator that gives all cross-validation partitions. \n",
    "        for train_index, test_index in outer_cv.split(features):\n",
    "            \n",
    "            #Split the data between train and test sets\n",
    "            train_features, test_features = features[train_index], features[test_index]\n",
    "            train_target, test_target = target[train_index], target[test_index]\n",
    "            \n",
    "            \n",
    "            #When the fit() method is called, it will internally perform a grid search cross-validation. \n",
    "            #Once it finds the best hyperparameters, it will fit on complete training set using those parameters.\n",
    "            grid_search_estimator = GridSearchCV(estimator = learning_method['estimator'], \n",
    "                           param_grid = learning_method['hyperparameter_grid'], \n",
    "                           cv = inner_cv, \n",
    "                           scoring = inner_scoring,\n",
    "                           #When n_jobs is -1, all CPUs are used to run cross-validation in parallel\n",
    "                           n_jobs=-1)\n",
    "            \n",
    "            grid_search_estimator.fit(train_features, train_target)\n",
    "            best_parameters = grid_search_estimator.best_params_\n",
    "            learning_method_results['best_parameters'].append(best_parameters)\n",
    "            \n",
    "            #Prediction using the best estimator selected via Grid Search CV\n",
    "            train_prediction = grid_search_estimator.predict(train_features)\n",
    "            test_prediction = grid_search_estimator.predict(test_features)\n",
    "            \n",
    "            \n",
    "            #Calculating R-Squared score\n",
    "            train_r2 = r2_score(y_true = train_target, y_pred = train_prediction)\n",
    "            test_r2 = r2_score(y_true = test_target, y_pred = test_prediction)\n",
    "            \n",
    "            learning_method_results['train_scores']['R-Squared'].append(train_r2)\n",
    "            learning_method_results['test_scores']['R-Squared'].append(test_r2)\n",
    "            \n",
    "            #Calculating RMSE score\n",
    "            train_rmse =  mean_squared_error(y_true = train_target, y_pred = train_prediction, squared=False)\n",
    "            test_rmse = mean_squared_error(y_true = test_target, y_pred = test_prediction, squared=False)\n",
    "            \n",
    "            learning_method_results['train_scores']['RMSE'].append(train_rmse)\n",
    "            learning_method_results['test_scores']['RMSE'].append(test_rmse)\n",
    "            \n",
    "        \n",
    "            \n",
    "        #Stores results for a particular learning method\n",
    "        results[learning_method['name']] = learning_method_results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Receives the nested cv results for a specific dataset and transform them into more readeable dataframes\n",
    "def extract_nestedcv_results(results):\n",
    "    \n",
    "    learning_methods_names = ['OLS', 'RIDGE', 'LASSO', 'PLS', 'SVR']\n",
    "    \n",
    "    #Groups test scores of every learning method in one dictionary per metric.\n",
    "    train_r2 = {method_name:results[method_name]['train_scores']['R-Squared'] for method_name in learning_methods_names} \n",
    "    train_rmse = {method_name:results[method_name]['train_scores']['RMSE'] for method_name in learning_methods_names}\n",
    "    \n",
    "    #Groups test scores of every learning method in one dictionary per metric.\n",
    "    test_r2 = {method_name:results[method_name]['test_scores']['R-Squared'] for method_name in learning_methods_names} \n",
    "    test_rmse = {method_name:results[method_name]['test_scores']['RMSE'] for method_name in learning_methods_names}\n",
    "    \n",
    "    \n",
    "    #For each learning algorithm, groups best parameters selected in each iteration of Nested CV outer loop\n",
    "    best_parameters = {method_name:results[method_name]['best_parameters'] for method_name in learning_methods_names}\n",
    "    \n",
    "    return {'train_r2': pd.DataFrame(train_r2), 'train_rmse': pd.DataFrame(train_rmse),\n",
    "           'test_r2': pd.DataFrame(test_r2), 'test_rmse': pd.DataFrame(test_rmse), \n",
    "           'best_parameters': pd.DataFrame(best_parameters)}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Non-nested k-Fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_nested_kfold_cv(features, target, k_value=10):\n",
    "    \"\"\"\n",
    "    Performs non-nested k-fold cross-validation over the given dataset, for each learning method defined.\n",
    "    First, an hyperpameter optimization cross-validation is performed. After that, a performance\n",
    "    evaluation cross-validation loop is performed. This is for every learning method defined.\n",
    "    \n",
    "    Returns a dictionary containing the performance scores, for both train and test datasets, for every learning method.\n",
    "    \n",
    "    Parameters:\n",
    "    features: A numpy array of shape (n_samples, n_features) containing dataset features.\n",
    "    target: A numpy array of shape (n_samples, n_features) containing dataset target variable.\n",
    "    k_value: A integer number indicating the number of folds the dataset will be splitted into by the k-fold cv loops.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with keys 'test_r2', 'train_r2', 'test_rmse', 'train_rmse', 'best_hyperparameters'. The value of 'test_r2' \n",
    "    is another dictionary that associates learning methods ('SVR', 'PLS', ..., 'OLS') with its performance scores.\n",
    "    \"\"\"\n",
    "    #Score metric used for hyperparameter optimization in inner CV loop\n",
    "    inner_scoring = 'neg_root_mean_squared_error'\n",
    "    \n",
    "    #Score metrics used in outer CV loop for generalization performance estimation of the learning method \n",
    "    outer_scoring = ['r2', 'neg_root_mean_squared_error']\n",
    "    \n",
    "    test_r2 = {}\n",
    "    train_r2 = {}\n",
    "    test_rmse = {}\n",
    "    train_rmse = {}\n",
    "    best_hyperparameters = {}\n",
    "    \n",
    "    learning_methods = get_learning_methods()\n",
    "    \n",
    "    for learning_method in learning_methods:\n",
    "        print(\"Modeling using\", learning_method['name'],\"method...\")\n",
    "        \n",
    "        #Defines the k-fold cv loop used to hyperparameter optimization\n",
    "        gridsearch_cv = KFold(n_splits=k_value, shuffle=True, random_state=seed + 1)\n",
    "        \n",
    "        #Defines the k-fold cv loop used to model (method/algorithm) evaluation.\n",
    "        #A different seed is used to avoid overfitting.\n",
    "        evaluation_cv = KFold(n_splits=k_value, shuffle=True, random_state=seed)\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator = learning_method['estimator'], \n",
    "                           param_grid = learning_method['hyperparameter_grid'], \n",
    "                           cv = gridsearch_cv, \n",
    "                           scoring = inner_scoring,\n",
    "                           #When n_jobs is -1, all CPUs are used to run cross-validation in parallel\n",
    "                           n_jobs=-1)\n",
    "        \n",
    "        #When the fit() method is called, it will internally perform a grid search cross-validation.\n",
    "        grid_search.fit(features, target)\n",
    "\n",
    "        #The best model/hyperparameters are evaluated on a cross-validation process\n",
    "        cv_results = cross_validate(estimator = grid_search.best_estimator_, \n",
    "                                          X = features, y = target, \n",
    "                                          cv = evaluation_cv, scoring = outer_scoring,\n",
    "                                          return_train_score=True)\n",
    "        \n",
    "        test_r2[learning_method['name']] = cv_results['test_r2'].tolist()\n",
    "        train_r2[learning_method['name']] = cv_results['train_r2'].tolist()\n",
    "        \n",
    "        #Inside CV, the RSME score is managed as a negative RMSE. Multiplying it by -1 will turn it into the usual positive RMSE  \n",
    "        test_rmse[learning_method['name']] = (cv_results['test_neg_root_mean_squared_error']*-1).tolist() \n",
    "        train_rmse[learning_method['name']] = (cv_results['train_neg_root_mean_squared_error']*-1).tolist()\n",
    "        \n",
    "        \n",
    "        best_hyperparameters[learning_method['name']] = grid_search.best_params_\n",
    "    \n",
    "    \n",
    "    return {'train_r2': train_r2, 'train_rmse': train_rmse, \n",
    "            'test_r2': test_r2, 'test_rmse':test_rmse, \n",
    "            'best_hyperparameters': best_hyperparameters}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5x2 Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_nested_5x2_cv(features, target):\n",
    "    \"\"\"\n",
    "    Performs non-nested 5x2 cross-validation over the given dataset, for each learning method defined.\n",
    "    First, an hyperpameter optimization cross-validation is performed. After that, a performance\n",
    "    evaluation cross-validation loop is performed. This is for every learning method defined.\n",
    "    \n",
    "    Returns a dictionary containing the performance scores, for both train and test datasets, for every learning method.\n",
    "    \n",
    "    Parameters:\n",
    "    features: A numpy array of shape (n_samples, n_features) containing dataset features.\n",
    "    target: A numpy array of shape (n_samples, n_features) containing dataset target variable.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with keys 'test_r2', 'train_r2', 'test_rmse', 'train_rmse', 'best_hyperparameters'. The value of 'test_r2' \n",
    "    is another dictionary that associates learning methods ('SVR', 'PLS', ..., 'OLS') with its performance scores.\n",
    "    \"\"\"\n",
    "    #Score metric used for hyperparameter optimization in inner CV loop\n",
    "    inner_scoring = 'neg_root_mean_squared_error'\n",
    "    \n",
    "    #Score metrics used in outer CV loop for generalization performance estimation of the learning method \n",
    "    outer_scoring = ['r2', 'neg_root_mean_squared_error']\n",
    "    \n",
    "    test_r2 = {}\n",
    "    train_r2 = {}\n",
    "    test_rmse = {}\n",
    "    train_rmse = {}\n",
    "    best_hyperparameters = {}\n",
    "    \n",
    "    learning_methods = get_learning_methods()\n",
    "    \n",
    "    for learning_method in learning_methods:\n",
    "        \n",
    "        print(\"Modeling using\", learning_method['name'],\"method...\")\n",
    "        #Defines the k-fold cv loop used to hyperparameter optimization\n",
    "        gridsearch_cv = FiveForTwoKFold(features, seed + 1)\n",
    "        \n",
    "        #Defines the k-fold cv loop used to model (method/algorithm) evaluation.\n",
    "        #A different seed is used to avoid overfitting.\n",
    "        evaluation_cv = FiveForTwoKFold(features, seed)\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator = learning_method['estimator'], \n",
    "                           param_grid = learning_method['hyperparameter_grid'], \n",
    "                           cv = gridsearch_cv, \n",
    "                           scoring = inner_scoring,\n",
    "                           #When n_jobs is -1, all CPUs are used to run cross-validation in parallel\n",
    "                           n_jobs=-1)\n",
    "        \n",
    "        #When the fit() method is called, it will internally perform a grid search cross-validation.\n",
    "        grid_search.fit(features, target)\n",
    "\n",
    "        #The best model/hyperparameters are evaluated on a cross-validation process\n",
    "        cv_results = cross_validate(estimator = grid_search.best_estimator_, \n",
    "                                          X = features, y = target, \n",
    "                                          cv = evaluation_cv, scoring = outer_scoring,\n",
    "                                          return_train_score=True)\n",
    "        \n",
    "        test_r2[learning_method['name']] = cv_results['test_r2'].tolist()\n",
    "        train_r2[learning_method['name']] = cv_results['train_r2'].tolist()\n",
    "        \n",
    "        #Inside CV, the RSME score is managed as a negative RMSE. Multiplying it by -1 will turn it into the usual positive RMSE  \n",
    "        test_rmse[learning_method['name']] = (cv_results['test_neg_root_mean_squared_error']*-1).tolist() \n",
    "        train_rmse[learning_method['name']] = (cv_results['train_neg_root_mean_squared_error']*-1).tolist()\n",
    "        \n",
    "        \n",
    "        best_hyperparameters[learning_method['name']] = grid_search.best_params_\n",
    "        \n",
    "        \n",
    "    \n",
    "    return {'train_r2': train_r2, 'train_rmse': train_rmse, \n",
    "            'test_r2': test_r2, 'test_rmse':test_rmse, \n",
    "            'best_hyperparameters': best_hyperparameters}\n",
    "\n",
    "\n",
    "#A methods that implements a similar behaviour to that of scikit KFold object. \n",
    "#It generate pairs of train and test sets, but implementing on 5x2 Cross-validation logic.\n",
    "#Roughly equivalent to five 2-Fold CV loops.\n",
    "def FiveForTwoKFold(data, seed):\n",
    "    for i in range(5):\n",
    "        kfold = KFold(n_splits=2, shuffle=True, random_state=seed + i)\n",
    "        for train_index, test_index in kfold.split(data):\n",
    "            yield train_index, test_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Experiment 3: Using 40 most relevant descriptors based on ranking generated by feature selection algorithm SURF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each evaluation method of two cross-validation loops, one for hyperparameter optimization, and one for model (learning algorithms) evaluation. Three evaluation methods were used:\n",
    "- Two Nested 10-Fold CV loops.\n",
    "- Two Non-nested 5-Fold CV loops.\n",
    "- Two non-nested 5x2 CV loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "    nested_cv_results = {}\n",
    "    five_fold_cv_results = {}\n",
    "    five_two_cv_results = {}\n",
    "    \n",
    "    for dataset in datasets():\n",
    "        print(\"Running experiments in dataset \", dataset['name'])\n",
    "        print(\"Nested CV validation method...\")\n",
    "        nested_cv_results[dataset['name']] = nested_cv(dataset['features'], dataset['target'])\n",
    "        print(\"5-Fold CV validation method...\")\n",
    "        five_fold_cv_results[dataset['name']] =  non_nested_kfold_cv(dataset['features'], dataset['target'], k_value=5)\n",
    "        print(\"5x2 CV validation method...\")\n",
    "        five_two_cv_results[dataset['name']] = non_nested_5x2_cv(dataset['features'], dataset['target'])\n",
    "    \n",
    "    return {'nested_cv': nested_cv_results, '5cv': five_fold_cv_results, '5x2cv': five_two_cv_results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments in dataset  p1STN\n",
      "Nested CV validation method...\n",
      "Modeling using OLS method...\n",
      "Modeling using RIDGE method...\n",
      "Modeling using LASSO method...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-75f7548aae69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-70-9ff89cfb6bdd>\u001b[0m in \u001b[0;36mrun_experiments\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Running experiments in dataset \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nested CV validation method...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mnested_cv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnested_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"5-Fold CV validation method...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mfive_fold_cv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnon_nested_kfold_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-22f0c9578984>\u001b[0m in \u001b[0;36mnested_cv\u001b[1;34m(features, target)\u001b[0m\n\u001b[0;32m     51\u001b[0m                            n_jobs=-1)\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mgrid_search_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[0mbest_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mlearning_method_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'best_parameters'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin\\.conda\\envs\\scikit-jupyter\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin\\.conda\\envs\\scikit-jupyter\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin\\.conda\\envs\\scikit-jupyter\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin\\.conda\\envs\\scikit-jupyter\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin\\.conda\\envs\\scikit-jupyter\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin\\.conda\\envs\\scikit-jupyter\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin\\.conda\\envs\\scikit-jupyter\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\benjamin\\.conda\\envs\\scikit-jupyter\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = run_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serializing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dumps a dictionary with the results into a text file so it can be loaded later in Python.\n",
    "def dump_results(results, filename):\n",
    "    with open(filename, 'wb') as results_file:\n",
    "        pickle.dump(results, results_file)\n",
    "\n",
    "    loaded_results = load_dumped_results(filename)\n",
    "\n",
    "    #If the original results and the dumped ones are not the same\n",
    "    if(results != loaded_results):\n",
    "        raise Exception('There was a error. The loaded dumped results are not the same as the original.')\n",
    "        \n",
    "#Loads the dumped results\n",
    "def load_dumped_results(filename):\n",
    "    with open(filename, 'rb') as results_file:\n",
    "        loaded_results = pickle.load(results_file)\n",
    "    return loaded_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results(results['nested_cv'], '../../results/modeling/nestedCV.pickle')\n",
    "dump_results(results['5cv'], '../../results/modeling/5CV.pickle')\n",
    "dump_results(results['5x2cv'], '../../results/modeling/5x2CV.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading serialized results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested = load_dumped_results('../../results/modeling/experiment_3/nestedCV.pickle')\n",
    "five_fold = load_dumped_results('../../results/modeling/experiment_3/5CV.pickle')\n",
    "five_two = load_dumped_results('../../results/modeling/experiment_3/5x2CV.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2':    OLS     RIDGE     LASSO       PLS       SVR\n",
       " 0  1.0  0.537851  0.585505  0.533128  0.594749\n",
       " 1  1.0  0.554107  0.590958  0.575337  0.575494\n",
       " 2  1.0  0.573481  0.642510  0.648507  0.670650\n",
       " 3  1.0  0.501171  0.547794  0.501368  0.632421\n",
       " 4  1.0  0.580820  0.633792  0.585057  0.610606\n",
       " 5  1.0  0.541077  0.587824  0.539259  0.579555\n",
       " 6  1.0  0.553775  0.610992  0.548925  0.641866\n",
       " 7  1.0  0.496760  0.527098  0.500846  0.541230\n",
       " 8  1.0  0.549366  0.592715  0.545311  0.588007\n",
       " 9  1.0  0.614908  0.660139  0.641213  0.616703,\n",
       " 'train_rmse':             OLS     RIDGE     LASSO       PLS       SVR\n",
       " 0  1.948881e-14  1.184657  1.121918  1.190695  1.109337\n",
       " 1  1.079688e-14  1.142587  1.094355  1.115054  1.114848\n",
       " 2  1.089972e-14  1.079020  0.987853  0.979533  0.948177\n",
       " 3  1.235693e-14  1.167350  1.111459  1.167119  1.002076\n",
       " 4  1.640612e-14  1.051340  0.982669  1.046013  1.013299\n",
       " 5  1.999266e-14  1.150600  1.090424  1.152876  1.101307\n",
       " 6  2.108512e-14  1.135476  1.060181  1.141630  1.017241\n",
       " 7  2.545551e-14  1.153709  1.118392  1.149016  1.101556\n",
       " 8  1.195445e-14  1.153440  1.096560  1.158618  1.102879\n",
       " 9  1.580633e-14  1.036803  0.974013  1.000766  1.034384,\n",
       " 'test_r2':           OLS     RIDGE     LASSO       PLS       SVR\n",
       " 0  -40.273223  0.638905  0.590420  0.575190  0.706452\n",
       " 1  -69.289232  0.069507  0.143847 -0.196447  0.108255\n",
       " 2   -5.825554 -0.209216 -0.560269 -1.388095 -0.299058\n",
       " 3  -12.833919  0.764019  0.665672  0.755125  0.590843\n",
       " 4   -1.583745  0.245675  0.137576  0.231000 -0.124736\n",
       " 5  -10.114939  0.535208  0.524909  0.505849  0.605367\n",
       " 6  -34.156488  0.359690  0.158501  0.154191  0.312181\n",
       " 7  -21.868020  0.709921  0.725378  0.739152  0.704801\n",
       " 8 -173.635200 -2.326939 -2.627699 -2.884494 -1.491509\n",
       " 9   -8.708934 -0.236291 -0.322577 -0.642917 -0.075140,\n",
       " 'test_rmse':         OLS     RIDGE     LASSO       PLS       SVR\n",
       " 0  7.183873  0.671948  0.715639  0.728823  0.605849\n",
       " 1  9.897226  1.138743  1.092307  1.291266  1.114781\n",
       " 2  3.844128  1.618009  1.837929  2.273813  1.677039\n",
       " 3  7.012815  0.915922  1.090200  0.933023  1.206048\n",
       " 4  3.421164  1.848538  1.976558  1.866432  2.257223\n",
       " 5  4.916807  1.005447  1.016525  1.036716  0.926459\n",
       " 6  8.663666  1.169214  1.340373  1.343802  1.211814\n",
       " 7  9.887405  1.113593  1.083516  1.055995  1.123377\n",
       " 8  7.116474  0.982249  1.025686  1.061369  0.850022\n",
       " 9  5.320558  1.898592  1.963731  2.188665  1.770533,\n",
       " 'best_parameters':   OLS             RIDGE           LASSO                  PLS  \\\n",
       " 0  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 2}   \n",
       " 1  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 2}   \n",
       " 2  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 3}   \n",
       " 3  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 2}   \n",
       " 4  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 2}   \n",
       " 5  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 2}   \n",
       " 6  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 2}   \n",
       " 7  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 2}   \n",
       " 8  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 2}   \n",
       " 9  {}  {'alpha': 100.0}  {'alpha': 0.1}  {'n_components': 2}   \n",
       " \n",
       "                                                  SVR  \n",
       " 0  {'C': 1.0, 'epsilon': 1.0, 'gamma': 0.01, 'ker...  \n",
       " 1  {'C': 1.0, 'epsilon': 1.2, 'gamma': 0.01, 'ker...  \n",
       " 2  {'C': 10.0, 'epsilon': 1.3, 'gamma': 0.01, 'ke...  \n",
       " 3  {'C': 10.0, 'epsilon': 1.2, 'gamma': 0.01, 'ke...  \n",
       " 4  {'C': 10.0, 'epsilon': 1.4, 'gamma': 0.01, 'ke...  \n",
       " 5  {'C': 1.0, 'epsilon': 1.0, 'gamma': 0.01, 'ker...  \n",
       " 6  {'C': 10.0, 'epsilon': 1.3, 'gamma': 0.01, 'ke...  \n",
       " 7  {'C': 1.0, 'epsilon': 1.2, 'gamma': 0.01, 'ker...  \n",
       " 8  {'C': 1.0, 'epsilon': 1.1, 'gamma': 0.01, 'ker...  \n",
       " 9  {'C': 10.0, 'epsilon': 1.1, 'gamma': 0.001, 'k...  }"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_nestedcv_results(nested['p1STN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': {'OLS': [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  'RIDGE': [0.5328759888818988,\n",
       "   0.5249585247820533,\n",
       "   0.5795151682566662,\n",
       "   0.5031194410987796,\n",
       "   0.6176207496765513],\n",
       "  'LASSO': [0.5838950208855633,\n",
       "   0.6165145674542734,\n",
       "   0.6511056507076516,\n",
       "   0.5612295353559367,\n",
       "   0.6740865468356408],\n",
       "  'PLS': [0.5513196258415923,\n",
       "   0.5587794388237339,\n",
       "   0.5820544062562146,\n",
       "   0.5007276225216402,\n",
       "   0.6395838952875907],\n",
       "  'SVR': [0.591215044964617,\n",
       "   0.6438707965438653,\n",
       "   0.6271238043902045,\n",
       "   0.5572130399745749,\n",
       "   0.6172277324745922]},\n",
       " 'train_rmse': {'OLS': [9.6650192989116e-15,\n",
       "   1.0409425229338591e-14,\n",
       "   1.1552915016131283e-14,\n",
       "   1.5986786371625798e-14,\n",
       "   1.123951039254908e-14],\n",
       "  'RIDGE': [1.202510994535023,\n",
       "   1.1263683678439689,\n",
       "   1.060853726520621,\n",
       "   1.1576433400626396,\n",
       "   1.0550452842978257],\n",
       "  'LASSO': [1.1349439558726384,\n",
       "   1.0120200496136467,\n",
       "   0.9663341042788642,\n",
       "   1.0878461226684197,\n",
       "   0.9740361734410984],\n",
       "  'PLS': [1.1785323190902381,\n",
       "   1.0855318050743745,\n",
       "   1.0576457163750526,\n",
       "   1.1604262510493106,\n",
       "   1.0242973196674217],\n",
       "  'SVR': [1.124916823578401,\n",
       "   0.9752556505122462,\n",
       "   0.9989935144282598,\n",
       "   1.092813839958985,\n",
       "   1.0555873435927106]},\n",
       " 'test_r2': {'OLS': [-15.078323193446732,\n",
       "   -3.966340678302122,\n",
       "   -3.713136684519065,\n",
       "   -11.266554316604754,\n",
       "   -28.09558063801379],\n",
       "  'RIDGE': [0.533002472896303,\n",
       "   0.42619382386127336,\n",
       "   0.3315111206351825,\n",
       "   0.598831361617109,\n",
       "   -0.2757931388358712],\n",
       "  'LASSO': [0.5425844627148233,\n",
       "   0.29342876528388506,\n",
       "   0.2612564510962342,\n",
       "   0.5557267412389245,\n",
       "   -0.4902447664365226],\n",
       "  'PLS': [0.47036730502455415,\n",
       "   0.3458995038502035,\n",
       "   0.30391721418574325,\n",
       "   0.5601964683335225,\n",
       "   -0.3247472105644573],\n",
       "  'SVR': [0.5284201408219606,\n",
       "   0.2473110489591287,\n",
       "   0.3849256454693495,\n",
       "   0.6936851509234376,\n",
       "   0.11244850543428309]},\n",
       " 'test_rmse': {'OLS': [5.231527409462363,\n",
       "   3.6753838772272167,\n",
       "   3.9750208470962978,\n",
       "   6.424714411969998,\n",
       "   7.037248071117525],\n",
       "  'RIDGE': [0.8915904712135149,\n",
       "   1.2493009241561204,\n",
       "   1.4970333890967666,\n",
       "   1.1618659424212539,\n",
       "   1.4735995408468563],\n",
       "  'LASSO': [0.8823961085343391,\n",
       "   1.3863166155059357,\n",
       "   1.573733696563645,\n",
       "   1.2226935493945403,\n",
       "   1.5926419436999781],\n",
       "  'PLS': [0.9495012074782463,\n",
       "   1.3338490729941848,\n",
       "   1.527618257105582,\n",
       "   1.216527387302767,\n",
       "   1.5016055102527757],\n",
       "  'SVR': [0.895954081326317,\n",
       "   1.4308437884098912,\n",
       "   1.4359793778338206,\n",
       "   1.0152583253254475,\n",
       "   1.2290969083489482]},\n",
       " 'best_hyperparameters': {'OLS': {},\n",
       "  'RIDGE': {'alpha': 100.0},\n",
       "  'LASSO': {'alpha': 0.1},\n",
       "  'PLS': {'n_components': 2},\n",
       "  'SVR': {'C': 1.0, 'epsilon': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(five_fold['p1STN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': {'OLS': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  'RIDGE': [0.451521439011905,\n",
       "   0.5797637985280175,\n",
       "   0.6642583510995648,\n",
       "   0.4764229205294682,\n",
       "   0.5604724840175108,\n",
       "   0.5636696688195953,\n",
       "   0.6289920416905208,\n",
       "   0.5720002234665076,\n",
       "   0.5784640907815628,\n",
       "   0.5289776989016479],\n",
       "  'LASSO': [0.5843796262871643,\n",
       "   0.6775094271260367,\n",
       "   0.8183656632975305,\n",
       "   0.6224341857998197,\n",
       "   0.6721292919076778,\n",
       "   0.6989824953719026,\n",
       "   0.82626966567817,\n",
       "   0.6642008537685531,\n",
       "   0.6991039561145906,\n",
       "   0.60537209184799],\n",
       "  'PLS': [0.5102077529833102,\n",
       "   0.6051302919863979,\n",
       "   0.7043041869450097,\n",
       "   0.5599477465230007,\n",
       "   0.6207063265483725,\n",
       "   0.5763167557804609,\n",
       "   0.6897306307710391,\n",
       "   0.6360099706325653,\n",
       "   0.6743540835001025,\n",
       "   0.5515395398558844],\n",
       "  'SVR': [0.6414819083359974,\n",
       "   0.557062916246898,\n",
       "   0.6994550230505172,\n",
       "   0.5658228608413511,\n",
       "   0.6091729044637222,\n",
       "   0.5960425606839395,\n",
       "   0.5950333627134763,\n",
       "   0.6965650847557234,\n",
       "   0.5824767409808285,\n",
       "   0.619981671212726]},\n",
       " 'train_rmse': {'OLS': [3.4257515000884513e-15,\n",
       "   4.401929455882885e-15,\n",
       "   3.371131474125594e-15,\n",
       "   6.572344375228229e-15,\n",
       "   8.104130166015155e-15,\n",
       "   2.4839818760406044e-15,\n",
       "   7.482169354852133e-15,\n",
       "   6.1840352633527214e-15,\n",
       "   4.3649222534651066e-15,\n",
       "   4.738309211329403e-15],\n",
       "  'RIDGE': [1.189968439092164,\n",
       "   1.0388440974033897,\n",
       "   0.9954330928927443,\n",
       "   1.1891632644105243,\n",
       "   1.1988182838819577,\n",
       "   1.0169289258189067,\n",
       "   0.9294377836157922,\n",
       "   1.151952000502135,\n",
       "   0.8859727174985222,\n",
       "   1.3219236196910484],\n",
       "  'LASSO': [1.035867074410107,\n",
       "   0.9100435109470468,\n",
       "   0.7321641183002462,\n",
       "   1.009828222272406,\n",
       "   1.0354082784450236,\n",
       "   0.8446538665645028,\n",
       "   0.6360137992657191,\n",
       "   1.0203576055382357,\n",
       "   0.7485335990537444,\n",
       "   1.2099837150826924],\n",
       "  'PLS': [1.124505458535091,\n",
       "   1.0070025138281213,\n",
       "   0.9341831997099873,\n",
       "   1.0901927663195923,\n",
       "   1.1136484657712635,\n",
       "   1.0020826510749856,\n",
       "   0.849959362492848,\n",
       "   1.0623248871613138,\n",
       "   0.778710227124657,\n",
       "   1.2898752412397243],\n",
       "  'SVR': [0.9620799253001454,\n",
       "   1.0665339055263698,\n",
       "   0.9418119619396832,\n",
       "   1.0828907593193493,\n",
       "   1.1304533788581848,\n",
       "   0.978477185894562,\n",
       "   0.9710427132424526,\n",
       "   0.9699411577326315,\n",
       "   0.8817457947343335,\n",
       "   1.187374996622854]},\n",
       " 'test_r2': {'OLS': [-1.9359737184161596,\n",
       "   -3.225087914620824,\n",
       "   -0.7822555895499106,\n",
       "   -6.1776393271998495,\n",
       "   -7.121332198007266,\n",
       "   -1.0207413047387175,\n",
       "   -2.046314626112049,\n",
       "   -5.122114389607562,\n",
       "   -3.4279332139986947,\n",
       "   -5.930611525193002],\n",
       "  'RIDGE': [0.37351196451806545,\n",
       "   0.31594625555387745,\n",
       "   0.3452939835207537,\n",
       "   0.4992021772848406,\n",
       "   0.46951072480795364,\n",
       "   0.44528417511603235,\n",
       "   0.28643990455641466,\n",
       "   0.3198113117959339,\n",
       "   0.4229932512093252,\n",
       "   0.45374402279515125],\n",
       "  'LASSO': [0.2176515120056799,\n",
       "   0.20618774301325848,\n",
       "   0.16525152248233654,\n",
       "   0.2343731024618938,\n",
       "   0.29588144064637745,\n",
       "   0.3766185519202352,\n",
       "   -0.017442258441418,\n",
       "   0.16921807735386252,\n",
       "   0.4423191739433955,\n",
       "   0.44592538159633643],\n",
       "  'PLS': [0.40849375466894944,\n",
       "   0.3164850084751959,\n",
       "   0.22178946179125192,\n",
       "   0.4086965636280947,\n",
       "   0.17502610436256372,\n",
       "   0.4535415551194988,\n",
       "   0.1170622526062639,\n",
       "   -0.03538782105766569,\n",
       "   0.378467471757707,\n",
       "   0.3699218795062613],\n",
       "  'SVR': [0.29186379056453426,\n",
       "   0.05044397673237,\n",
       "   0.3813859036208763,\n",
       "   0.5504053083740148,\n",
       "   0.5033631186388038,\n",
       "   0.49816466979333796,\n",
       "   0.48414779033922994,\n",
       "   0.13573668006790385,\n",
       "   0.40132702914379004,\n",
       "   0.6152222460957941]},\n",
       " 'test_rmse': {'OLS': [2.745868450976766,\n",
       "   3.3027331822539217,\n",
       "   2.193997680542241,\n",
       "   4.602568712432378,\n",
       "   4.3872919631005365,\n",
       "   2.5704886053649343,\n",
       "   3.073264858343749,\n",
       "   3.775543085679731,\n",
       "   4.053089169668774,\n",
       "   3.5924343339202465],\n",
       "  'RIDGE': [1.268411106292788,\n",
       "   1.328925781739193,\n",
       "   1.3297632835462867,\n",
       "   1.215739930508144,\n",
       "   1.1212984014049354,\n",
       "   1.3467767224226046,\n",
       "   1.4874003852008792,\n",
       "   1.2584715827793476,\n",
       "   1.4631069523312856,\n",
       "   1.0085586563704125],\n",
       "  'LASSO': [1.4174370131405125,\n",
       "   1.4315763494344684,\n",
       "   1.5015126285516507,\n",
       "   1.5032044624174137,\n",
       "   1.2918312755845867,\n",
       "   1.4277009891840593,\n",
       "   1.7761003423874773,\n",
       "   1.3908241711825304,\n",
       "   1.438396057713689,\n",
       "   1.0157508354508704],\n",
       "  'PLS': [1.2324897399565786,\n",
       "   1.328402355269062,\n",
       "   1.4497720579688698,\n",
       "   1.321036041721492,\n",
       "   1.39830851445708,\n",
       "   1.3367152249554244,\n",
       "   1.654541459801732,\n",
       "   1.5526738432212328,\n",
       "   1.5185096595250172,\n",
       "   1.0831790700470394],\n",
       "  'SVR': [1.348534452605351,\n",
       "   1.5657265329112164,\n",
       "   1.2925908503404235,\n",
       "   1.1519139893514987,\n",
       "   1.0849316603254977,\n",
       "   1.280975844581885,\n",
       "   1.2646643019112749,\n",
       "   1.4185732022767046,\n",
       "   1.4903231684858576,\n",
       "   0.8464631140016156]},\n",
       " 'best_hyperparameters': {'OLS': {},\n",
       "  'RIDGE': {'alpha': 100.0},\n",
       "  'LASSO': {'alpha': 0.1},\n",
       "  'PLS': {'n_components': 2},\n",
       "  'SVR': {'C': 10.0, 'epsilon': 1.3, 'gamma': 0.01, 'kernel': 'rbf'}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(five_two['p1STN'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
